{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of AD vs MCI vs NC Using the ResNet Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==3.0.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: bleach==6.2.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 2)) (6.2.0)\n",
      "Requirement already satisfied: certifi==2024.12.14 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 3)) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: colorama==0.4.6 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: cycler==0.12.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.11 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 9)) (1.8.11)\n",
      "Requirement already satisfied: decorator==5.1.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 10)) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 11)) (1.2.2)\n",
      "Requirement already satisfied: executing==2.1.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 12)) (2.1.0)\n",
      "Requirement already satisfied: filelock==3.16.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 13)) (3.16.1)\n",
      "Requirement already satisfied: fonttools==4.55.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 14)) (4.55.3)\n",
      "Requirement already satisfied: fsspec==2024.12.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 15)) (2024.12.0)\n",
      "Requirement already satisfied: idna==3.10 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 16)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 17)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.31.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 18)) (8.31.0)\n",
      "Requirement already satisfied: jedi==0.19.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 19)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.5 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 20)) (3.1.5)\n",
      "Requirement already satisfied: joblib==1.4.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 21)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 22)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 23)) (5.7.2)\n",
      "Requirement already satisfied: kaggle==1.6.17 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 24)) (1.6.17)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 25)) (1.4.8)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 26)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 27)) (3.10.0)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 28)) (0.1.7)\n",
      "Requirement already satisfied: mpmath==1.3.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 29)) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 30)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 31)) (3.4.2)\n",
      "Requirement already satisfied: numpy==2.2.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 32)) (2.2.1)\n",
      "Requirement already satisfied: opencv-python==4.10.0.84 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 33)) (4.10.0.84)\n",
      "Requirement already satisfied: packaging==24.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 34)) (24.2)\n",
      "Requirement already satisfied: parso==0.8.4 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 35)) (0.8.4)\n",
      "Requirement already satisfied: pillow==11.1.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 36)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 37)) (4.3.6)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 38)) (3.0.48)\n",
      "Requirement already satisfied: psutil==6.1.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 39)) (6.1.1)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 40)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 41)) (2.19.1)\n",
      "Requirement already satisfied: pyparsing==3.2.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 42)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 43)) (2.9.0.post0)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 44)) (26.2.0)\n",
      "Requirement already satisfied: requests==2.32.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 45)) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 46)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 47)) (1.15.1)\n",
      "Requirement already satisfied: six==1.17.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 48)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 49)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 50)) (1.13.1)\n",
      "Requirement already satisfied: text-unidecode==1.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 51)) (1.3)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 52)) (3.5.0)\n",
      "Requirement already satisfied: torch==2.5.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 53)) (2.5.1)\n",
      "Requirement already satisfied: torchinfo==1.8.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 54)) (1.8.0)\n",
      "Requirement already satisfied: torchvision==0.20.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 55)) (0.20.1)\n",
      "Requirement already satisfied: tornado==6.4.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 56)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 57)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 58)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 59)) (4.12.2)\n",
      "Requirement already satisfied: urllib3==2.3.0 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 60)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 61)) (0.2.13)\n",
      "Requirement already satisfied: webencodings==0.5.1 in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 62)) (0.5.1)\n",
      "Requirement already satisfied: openpyxl in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 63)) (3.1.5)\n",
      "Requirement already satisfied: nibabel in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 64)) (5.3.2)\n",
      "Requirement already satisfied: monai in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 65)) (1.3.2)\n",
      "Requirement already satisfied: pandas in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 66)) (2.2.3)\n",
      "Requirement already satisfied: torchio in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 67)) (0.20.5)\n",
      "Requirement already satisfied: fvcore in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 68)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: av in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 69)) (14.2.0)\n",
      "Requirement already satisfied: xlrd in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 71)) (2.0.1)\n",
      "Requirement already satisfied: einops in d:\\python-codes\\packages\\lib\\site-packages (from -r requirements.txt (line 72)) (0.8.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\python-codes\\packages\\lib\\site-packages (from jupyter_core==5.7.2->-r requirements.txt (line 23)) (308)\n",
      "Requirement already satisfied: python-slugify in d:\\python-codes\\packages\\lib\\site-packages (from kaggle==1.6.17->-r requirements.txt (line 24)) (8.0.4)\n",
      "Requirement already satisfied: et-xmlfile in d:\\python-codes\\packages\\lib\\site-packages (from openpyxl->-r requirements.txt (line 63)) (2.0.0)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in d:\\python-codes\\packages\\lib\\site-packages (from nibabel->-r requirements.txt (line 64)) (6.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python-codes\\packages\\lib\\site-packages (from pandas->-r requirements.txt (line 66)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\python-codes\\packages\\lib\\site-packages (from pandas->-r requirements.txt (line 66)) (2025.1)\n",
      "Requirement already satisfied: deprecated>=1.2 in d:\\python-codes\\packages\\lib\\site-packages (from torchio->-r requirements.txt (line 67)) (1.2.18)\n",
      "Requirement already satisfied: humanize>=0.1 in d:\\python-codes\\packages\\lib\\site-packages (from torchio->-r requirements.txt (line 67)) (4.12.2)\n",
      "Requirement already satisfied: rich>=10 in d:\\python-codes\\packages\\lib\\site-packages (from torchio->-r requirements.txt (line 67)) (13.9.4)\n",
      "Requirement already satisfied: simpleitk!=2.0.*,!=2.1.1.1,>=1.3 in d:\\python-codes\\packages\\lib\\site-packages (from torchio->-r requirements.txt (line 67)) (2.4.1)\n",
      "Requirement already satisfied: typer>=0.1 in d:\\python-codes\\packages\\lib\\site-packages (from torchio->-r requirements.txt (line 67)) (0.15.2)\n",
      "Requirement already satisfied: yacs>=0.1.6 in d:\\python-codes\\packages\\lib\\site-packages (from fvcore->-r requirements.txt (line 68)) (0.1.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\python-codes\\packages\\lib\\site-packages (from fvcore->-r requirements.txt (line 68)) (6.0.2)\n",
      "Requirement already satisfied: termcolor>=1.1 in d:\\python-codes\\packages\\lib\\site-packages (from fvcore->-r requirements.txt (line 68)) (3.0.0)\n",
      "Requirement already satisfied: tabulate in d:\\python-codes\\packages\\lib\\site-packages (from fvcore->-r requirements.txt (line 68)) (0.9.0)\n",
      "Requirement already satisfied: iopath>=0.1.7 in d:\\python-codes\\packages\\lib\\site-packages (from fvcore->-r requirements.txt (line 68)) (0.1.10)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in d:\\python-codes\\packages\\lib\\site-packages (from deprecated>=1.2->torchio->-r requirements.txt (line 67)) (1.17.2)\n",
      "Requirement already satisfied: portalocker in d:\\python-codes\\packages\\lib\\site-packages (from iopath>=0.1.7->fvcore->-r requirements.txt (line 68)) (3.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\python-codes\\packages\\lib\\site-packages (from rich>=10->torchio->-r requirements.txt (line 67)) (3.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\python-codes\\packages\\lib\\site-packages (from typer>=0.1->torchio->-r requirements.txt (line 67)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\python-codes\\packages\\lib\\site-packages (from typer>=0.1->torchio->-r requirements.txt (line 67)) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\python-codes\\packages\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10->torchio->-r requirements.txt (line 67)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python-codes\\packages\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing command: ['git', 'add', 'path_to_your_file']\n",
      "Error message: fatal: pathspec 'path_to_your_file' did not match any files\n",
      "\n",
      "Failed to add path_to_your_file to git.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import shutil\n",
    "import data_manager as DM\n",
    "# import torchvision.models as models\n",
    "import torchvision.models.video as models\n",
    "from torchvision.models.video import R3D_18_Weights, r3d_18\n",
    "import data_setup, engine\n",
    "from helper_functions import plot_loss_curves\n",
    "from data_setup import create_dataloaders\n",
    "import engine\n",
    "from monai.transforms import Resize\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "from helper_functions import plot_loss_curves\n",
    "import torchio as tio\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import scipy.io as sio\n",
    "import monai\n",
    "import nibabel as nib\n",
    "from Update_Git import git_add, git_commit, git_push\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the parrent path to current path because data is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "git_push() missing 1 required positional argument: 'branch_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m git_add(file_path)\n\u001b[0;32m      7\u001b[0m git_commit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdate main.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: git_push() missing 1 required positional argument: 'branch_name'"
     ]
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "parrent_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "sys.path.append(parrent_path)\n",
    "\n",
    "file_path = \"main.ipynb\"\n",
    "git_add(file_path)\n",
    "git_commit(\"Update main.ipynb\")\n",
    "git_push(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage data:\n",
    "\n",
    "✔ Read subject IDs from each sheet in Subject list.xlsx.\n",
    "\n",
    "✔ Create Data/AD, Data/MCI, Data/NC folders.\n",
    "\n",
    "✔ Find std_T1.nii for each subject inside ADNI/{subject_id}/.\n",
    "\n",
    "✔ Copy & renames the file to Data/{category}/{subject_id}.nii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Subject list.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m    os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrm -r Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m source_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mDM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python-codes\\Test_codes\\PyTorch\\ViT3D for AD MCI NC\\data_manager.py:15\u001b[0m, in \u001b[0;36mcopy_data\u001b[1;34m(excel_file, source_root, source_dir, destination_root, categories)\u001b[0m\n\u001b[0;32m     12\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, category), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Read Excel file and process each sheet\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m xls \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m xls\u001b[38;5;241m.\u001b[39msheet_names:\n",
      "File \u001b[1;32md:\\Python-codes\\packages\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32md:\\Python-codes\\packages\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Python-codes\\packages\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Subject list.xlsx'"
     ]
    }
   ],
   "source": [
    "categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "excel_file = \"../Subject list.xlsx\"\n",
    "source_root = \"ADNI\"\n",
    "destination_root = \"Data\"\n",
    "if os.path.join(destination_root):\n",
    "   os.system('rm -r Data')\n",
    "source_dir = \"../\"\n",
    "DM.copy_data(excel_file,source_root,source_dir, destination_root,categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many subjects do we have in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"Data\"\n",
    "\n",
    "for c in categories:\n",
    "    path_train = os.path.join(data_root, 'train', c)\n",
    "    path_test = os.path.join(data_root, 'test', c)\n",
    "\n",
    "    num_train_files = len(os.listdir(path_train))\n",
    "    print(f\"{c} train: {num_train_files} files\")\n",
    "\n",
    "    num_test_files = len(os.listdir(path_test))\n",
    "    print(f\"{c} test: {num_test_files} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader: Prepare the data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is the ViT default transformation?\n",
    "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)\n",
    "transform = pretrained_vit_weights.transforms()\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "# pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)\n",
    "# transform = pretrained_vit_weights.transforms()\n",
    "# print(transform)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "print(f\"transform: {transform}\")\n",
    "\n",
    "# Augmentaed dataset to be added to the main dataset\n",
    "augmentation_transform = transforms.Compose([\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Adjust colors\n",
    "    transforms.RandomHorizontalFlip(p=1),  # Random horizontal flip\n",
    "    transforms.RandomVerticalFlip(p=0.3),  # Random vertical flip\n",
    "    transforms.RandomRotation(degrees=15, interpolation=InterpolationMode.BICUBIC),  # Random rotation\n",
    "    transforms.Resize(size=256, interpolation=InterpolationMode.BILINEAR),  # Resize to 256\n",
    "    transforms.CenterCrop(size=224),  # Center crop to 224x224\n",
    "    #transforms.ToTensor(),  # Convert image to tensor\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "train_data_path = os.path.join(data_root,\"train\")\n",
    "test_data_path = os.path.join(data_root,\"test\")\n",
    "\n",
    "train_dataloader_pretrained, test_dataloader_pretrained, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_data_path, \n",
    "    test_dir=test_data_path,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    # augmentation_transform=augmentation_transform\n",
    ")\n",
    "\n",
    "print(' ')\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "print(' ')\n",
    "print(\"Number of training data: \", len(train_dataloader_pretrained) * batch_size)\n",
    "print(\"Number of testing data: \", len(test_dataloader_pretrained) * batch_size)\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataloader_pretrained))\n",
    "print(image_batch.shape, label_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 9 images (first slice of each)\n",
    "num_images = 6\n",
    "image_batch_np = image_batch.cpu()  # Move to CPU\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 9))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):  \n",
    "    img = image_batch_np[i, 30]  # Take one slice (shape: 1, 224, 224)\n",
    "    img_np = img.numpy().transpose(1, 2, 0)  # Convert from (C, H, W) → (H, W, C)\n",
    "    ax.imshow(img_np)  # Show RGB image\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(f\"Label: {class_names[label_batch[i].item()]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ViT model\n",
    "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights).to(device)\n",
    "\n",
    "# Freeze pretrained weights\n",
    "for parameter in pretrained_vit.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "# Modify the conv_proj to accept 3-channel images (RGB slices)\n",
    "pretrained_vit.conv_proj = nn.Conv2d(\n",
    "    in_channels=1,  # 3-channel input (RGB slices)\n",
    "    out_channels=768,  # Output channels must match ViT embeddings\n",
    "    kernel_size=16,\n",
    "    stride=16\n",
    ").to(device)\n",
    "\n",
    "# Remove the classification head as we'll define our own\n",
    "pretrained_vit.heads = nn.Identity()\n",
    "\n",
    "# Define the ViT3D model with aggregation\n",
    "class ViT3D(nn.Module):\n",
    "    def __init__(self, vit_model, num_slices=79, num_classes=3, aggregation=\"mean\"):\n",
    "        super(ViT3D, self).__init__()\n",
    "        self.vit = vit_model\n",
    "        self.num_slices = num_slices\n",
    "        self.aggregation = aggregation  # \"mean\", \"max\" for feature aggregation\n",
    "        \n",
    "        # Fully connected classification head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(768, num_classes)  # Output dimension matches the number of classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, num_slices, C, H, W = x.shape  # Shape: (B, 79, 3, 224, 224)\n",
    "        x = x.view(batch_size * num_slices, C, H, W)  # Flatten slices: (B*79, 3, 224, 224)\n",
    "        \n",
    "        features = self.vit(x)  # Shape: (B*79, 768) after passing through ViT\n",
    "        \n",
    "        features = features.view(batch_size, num_slices, -1)  # Reshape to (B, 79, 768)\n",
    "\n",
    "        # Aggregate features across slices using specified method\n",
    "        if self.aggregation == \"mean\":\n",
    "            features = torch.mean(features, dim=1)  # Mean pooling across slices\n",
    "        elif self.aggregation == \"max\":\n",
    "            features, _ = torch.max(features, dim=1)  # Max pooling across slices\n",
    "        else:\n",
    "            raise ValueError(\"Invalid aggregation method. Choose 'mean' or 'max'.\")\n",
    "\n",
    "        return self.fc(features)  # Final classification step\n",
    "    \n",
    "# Initialize the ViT3D model\n",
    "vit3d_model = ViT3D(pretrained_vit, num_slices=79, num_classes=3, aggregation=\"mean\").to(device)\n",
    "\n",
    "# Print the model summary\n",
    "summary(model=vit3d_model,\n",
    "        input_size=(8, 79, 1, 224, 224),  # Input shape: (batch_size, slices, channels, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the device\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Working on device: {device}\")\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(vit3d_model.parameters(), lr=1e-64, weight_decay=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the classifier head of the pretrained ViT feature extractor model\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "pretrained_RN_18_results = engine.train(\n",
    "    model=vit3d_model,\n",
    "    train_dataloader=train_dataloader_pretrained,\n",
    "    test_dataloader=test_dataloader_pretrained,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=5,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(vit3d_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

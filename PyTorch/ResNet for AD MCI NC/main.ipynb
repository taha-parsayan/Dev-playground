{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of AD vs MCI vs NC Using the ResNet Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get update\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install monai\n",
    "! pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import shutil\n",
    "import data_manager as DM\n",
    "# import torchvision.models as models\n",
    "import torchvision.models.video as models\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "import data_setup, engine\n",
    "from helper_functions import plot_loss_curves\n",
    "from data_setup import create_dataloaders\n",
    "import engine\n",
    "from monai.transforms import Resize\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "from helper_functions import plot_loss_curves\n",
    "import torchio as tio\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from Update_Git import git_add, git_commit, git_push\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the parrent path to current path because data is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "parrent_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "sys.path.append(parrent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing command: ['git', 'commit', '-m', 'Updated dahsbord test 1']\n",
      "Error message: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(current_path, 'main.ipynb')\n",
    "git_add(file_path)\n",
    "git_commit('Updated dahsbord test 1')\n",
    "git_push('main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage data:\n",
    "\n",
    "✔ Read subject IDs from each sheet in Subject list.xlsx.\n",
    "\n",
    "✔ Create Data/AD, Data/MCI, Data/NC folders.\n",
    "\n",
    "✔ Find std_T1.nii for each subject inside ADNI/{subject_id}/.\n",
    "\n",
    "✔ Copy & renames the file to Data/{category}/{subject_id}.nii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel_file = \"../Subject list.xlsx\"\n",
    "# source_root = \"ADNI\"\n",
    "# destination_root = \"Data\"\n",
    "# categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "# DM.copy_data(excel_file,source_root,destination_root,categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many subjects do we have in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"Data\"\n",
    "categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "\n",
    "for c in categories:\n",
    "    path_train = os.path.join(data_root, 'train', c)\n",
    "    path_test = os.path.join(data_root, 'test', c)\n",
    "\n",
    "    num_train_files = len(os.listdir(path_train))\n",
    "    print(f\"{c} train: {num_train_files} files\")\n",
    "\n",
    "    num_test_files = len(os.listdir(path_test))\n",
    "    print(f\"{c} test: {num_test_files} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Load pretrained 3D ResNet (r3d_18)\n",
    "resnet3d = models.r3d_18(weights=R3D_18_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Freeze all layers for transfer learning (do this first!)\n",
    "for param in resnet3d.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the first convolution layer to accept 1-channel 3D MRI input\n",
    "resnet3d.stem[0] = nn.Conv3d(\n",
    "    in_channels=1,  # Change to 1 channel for grayscale MRI images\n",
    "    out_channels=64,  # Keeping the same output channels as the original model\n",
    "    kernel_size=(7, 7, 7),  # The size of the 3D convolution filter\n",
    "    stride=(2, 2, 2),  # reducing the spatial resolution by half at each step\n",
    "    padding=(3, 3, 3),  # Adds zero-padding around the input before applying the convolution\n",
    "    bias=True  # Whether the layer should learn a bias term (default = False)\n",
    ").to(device)\n",
    "\n",
    "# Modify the final fully connected layer (fc) for 3-class classification (AD, MCI, NC)\n",
    "resnet3d.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(in_features=512, out_features=3)  # 3-class output\n",
    ").to(device)\n",
    "\n",
    "'''\n",
    "Output size = ((input size + 2*padding size - kernel size)stride size) - 1\n",
    "'''\n",
    "\n",
    "# Print model summary\n",
    "summary(model=resnet3d,\n",
    "        input_size=(16, 1, 79, 95, 79), # (batch_size, channels, depth, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader: Prepare the data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # Resize(spatial_size=(60, 60, 60)),\n",
    "    transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min())),  # Normalize to [0,1]\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]) \n",
    "])\n",
    "\n",
    "\n",
    "# Augmentaed dataset to be added to the main dataset\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min())),  # Normalize to [0,1]\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229]),\n",
    "    transforms.RandomHorizontalFlip(p=1),  # Random horizontal flip\n",
    "    transforms.RandomVerticalFlip(p=0.3),  # Random vertical flip\n",
    "    transforms.RandomRotation(degrees=15, interpolation=InterpolationMode.NEAREST ),  # Random rotation\n",
    "])\n",
    "\n",
    "\n",
    "# Data loader\n",
    "train_data_path = os.path.join(data_root,\"train\")\n",
    "test_data_path = os.path.join(data_root,\"test\")\n",
    "\n",
    "train_dataloader_pretrained, test_dataloader_pretrained, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_data_path, \n",
    "    test_dir=test_data_path,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    augmentation_transform=augmentation_transform\n",
    ")\n",
    "\n",
    "print(' ')\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "print(' ')\n",
    "print(\"Number of training data: \", len(train_dataloader_pretrained) * batch_size)\n",
    "print(\"Number of testing data: \", len(test_dataloader_pretrained) * batch_size)\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataloader_pretrained))\n",
    "print(image_batch.shape, label_batch.shape)\n",
    "\n",
    "# Choose 9 random images from the batch\n",
    "num_images = 9\n",
    "batch_size = image_batch.shape[0]\n",
    "random_indices = torch.randint(0, batch_size, (num_images,))  # Select 9 random indices\n",
    "\n",
    "# Mid slice index along the third dimension (depth)\n",
    "mid_slice_idx = image_batch.shape[3] // 2\n",
    "\n",
    "# Create 3x3 plot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = random_indices[i]  # Get a random index\n",
    "    img = image_batch[idx, 0, :, :, mid_slice_idx].detach().cpu().numpy()  # Extract middle slice\n",
    "    \n",
    "    ax.imshow(img, cmap='gray')  \n",
    "    ax.set_title(f'Image {idx+1}')\n",
    "    ax.axis('off')  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Working on device: {device}\")\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=resnet3d.parameters(), lr=1e-6, weight_decay=1e-7)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the classifier head of the pretrained ViT feature extractor model\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "pretrained_RN_18_results = engine.train(\n",
    "    model=resnet3d,\n",
    "    train_dataloader=train_dataloader_pretrained,\n",
    "    test_dataloader=test_dataloader_pretrained,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=20,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(pretrained_RN_18_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

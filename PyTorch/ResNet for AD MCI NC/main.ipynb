{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of AD vs MCI vs NC Using the ResNet Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in d:\\python-codes\\packages\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in d:\\python-codes\\packages\\lib\\site-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9 in d:\\python-codes\\packages\\lib\\site-packages (from monai) (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in d:\\python-codes\\packages\\lib\\site-packages (from torch>=1.9->monai) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python-codes\\packages\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import shutil\n",
    "import data_manager as DM\n",
    "#import torchvision.models as models\n",
    "import torchvision.models.video as models\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "import data_setup, engine\n",
    "from helper_functions import plot_loss_curves\n",
    "from data_setup import create_dataloaders\n",
    "import engine\n",
    "from monai.transforms import Resize\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the parrent path to current path because data is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_path = os.getcwd()\n",
    "parrent_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "grand_parrent_path = os.path.abspath(os.path.join(current_path, '../..'))\n",
    "sys.path.append(parrent_path)\n",
    "sys.path.append(grand_parrent_path)\n",
    "\n",
    "from Update_Git import git_add, git_commit, git_push\n",
    "file_path = os.path.join('main.ipynb')\n",
    "# file_path = os.path.join('data_manager.py')\n",
    "# file_path = os.path.join('data_setup.py')\n",
    "# file_path = os.path.join('engine.py')\n",
    "# file_path = os.path.join('helper_functions.py')\n",
    "# file_path = os.path.join('model_builder.py')\n",
    "# file_path = os.path.join('predictions.py')\n",
    "# file_path = os.path.join('requirements.txt')\n",
    "\n",
    "git_add(file_path)\n",
    "git_commit('Updated main')\n",
    "git_push('main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage data:\n",
    "\n",
    "✔ Read subject IDs from each sheet in Subject list.xlsx.\n",
    "\n",
    "✔ Create Data/AD, Data/MCI, Data/NC folders.\n",
    "\n",
    "✔ Find std_T1.nii for each subject inside ADNI/{subject_id}/.\n",
    "\n",
    "✔ Copy & renames the file to Data/{category}/{subject_id}.nii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = \"../Subject list.xlsx\"\n",
    "source_root = \"ADNI\"\n",
    "destination_root = \"Data\"\n",
    "categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "\n",
    "DM.copy_data(excel_file,source_root,destination_root,categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many subjects do we have in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"Data\"\n",
    "categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "\n",
    "for c in categories:\n",
    "    path_train = os.path.join(data_root, 'train', c)\n",
    "    path_test = os.path.join(data_root, 'test', c)\n",
    "\n",
    "    num_train_files = len(os.listdir(path_train))\n",
    "    print(f\"{c} train: {num_train_files} files\")\n",
    "\n",
    "    num_test_files = len(os.listdir(path_test))\n",
    "    print(f\"{c} test: {num_test_files} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification model: ResNet3d\n",
    "\n",
    "ResNet50 is originally designed for 2D images, so modifying it for 3D MRI may not be optimal.\n",
    "A better alternative would be ResNet-3D variants, like **ResNet18-3D** or **ResNet50-3D** from torchvision.models.video.\n",
    "\n",
    "Image Dimensions (X, Y, Z): 79 x 95 x 79\n",
    "Series Length:  (1 volume per scan == static images)\n",
    "Voxel Dimensions (X, Y, Z): 2 x 2 x 2 Millimeters (standard MNI space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Load pretrained 3D ResNet (r3d_18)\n",
    "resnet3d = models.r3d_18(weights=R3D_18_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Freeze all layers for transfer learning (do this first!)\n",
    "for param in resnet3d.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the first convolution layer to accept 1-channel 3D MRI input\n",
    "resnet3d.stem[0] = nn.Conv3d(\n",
    "    in_channels=1,  # Change to 1 channel for grayscale MRI images\n",
    "    out_channels=64,  # Keeping the same output channels as the original model\n",
    "    kernel_size=(7, 7, 7),  # The size of the 3D convolution filter\n",
    "    stride=(2, 2, 2),  # reducing the spatial resolution by half at each step\n",
    "    padding=(3, 3, 3),  # Adds zero-padding around the input before applying the convolution\n",
    "    bias=False  # Whether the layer should learn a bias term (default = False)\n",
    ").to(device)\n",
    "\n",
    "# Modify the final fully connected layer (fc) for 3-class classification (AD, MCI, NC)\n",
    "resnet3d.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(in_features=512, out_features=3)  # 3-class output\n",
    ").to(device)\n",
    "\n",
    "'''\n",
    "Output size = ((input size + 2*padding size - kernel size)stride size) - 1\n",
    "'''\n",
    "\n",
    "# Print model summary\n",
    "summary(model=resnet3d,\n",
    "        input_size=(16, 1, 79, 95, 79), # (batch_size, channels, depth, height, width)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader: Prepare the data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Define the transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    # Resize(spatial_size=(64, 64, 64)),  # Resize to 64x64x64 for 3D images\n",
    "    # transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalization parameters\n",
    "])\n",
    "\n",
    "# Data loader\n",
    "train_data_path = os.path.join(\"Data\",\"train\")\n",
    "test_data_path = os.path.join(\"Data\",\"test\")\n",
    "\n",
    "train_dataloader_pretrained, test_dataloader_pretrained, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_data_path, \n",
    "    test_dir=test_data_path,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(' ')\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "print(' ')\n",
    "print(\"Number of training data: \", len(train_dataloader_pretrained) * batch_size)\n",
    "print(\"Number of testing data: \", len(test_dataloader_pretrained) * batch_size)\n",
    "\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataloader_pretrained))\n",
    "print(image_batch.shape, label_batch.shape)\n",
    "\n",
    "# image, label = image_batch[0], label_batch[0]\n",
    "# print(image.shape, label)\n",
    "\n",
    "# plt.imshow(image.permute(1, 2, 0))\n",
    "# plt.title(class_names[label])\n",
    "# plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Working on device: {device}\")\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=resnet3d.parameters(), lr=0.01, weight_decay=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the classifier head of the pretrained ViT feature extractor model\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "pretrained_RN_18_results = engine.train(\n",
    "    model=resnet3d,\n",
    "    train_dataloader=train_dataloader_pretrained,\n",
    "    test_dataloader=test_dataloader_pretrained,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=5,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

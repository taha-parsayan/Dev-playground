{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundementals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m venv packages\n",
    "\n",
    "Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass\n",
    "\n",
    ".\\packages\\Scripts\\Activate.ps1\n",
    "\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu118'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "7\n",
      "<class 'torch.Tensor'>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "print(scalar.item()) #get the value\n",
    "print(type(scalar))\n",
    "print(scalar.ndim) #dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 7])\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "print(vector)\n",
    "print(vector.ndim) #dimensions = 1 because it is a vecotr with 1 row\n",
    "print(vector.shape) #shape is the number of ellements inside = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "tensor([ 9, 10])\n",
      "tensor(9)\n",
      "tensor([ 8, 10])\n",
      "2\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "\n",
    "print(MATRIX)\n",
    "print(MATRIX[1])\n",
    "print(MATRIX[1,0])\n",
    "print(MATRIX[:,1])\n",
    "print(MATRIX.ndim) #dimensions = 1 because it is a vecotr with 1 row\n",
    "print(MATRIX.shape) #shape is the number of ellements inside = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 6, 9],\n",
      "        [2, 4, 5]])\n",
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  3  6  9\n",
      "2  2  4  5\n",
      "0    2\n",
      "1    6\n",
      "2    4\n",
      "Name: 1, dtype: int64\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "print(TENSOR[0])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(TENSOR[0])\n",
    "print(df)\n",
    "print(df[1])\n",
    "print(df[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2855, 0.3419, 0.4774, 0.2469],\n",
      "        [0.0560, 0.9875, 0.0659, 0.9844],\n",
      "        [0.4627, 0.3199, 0.6314, 0.6246]]) torch.float32\n",
      "torch.Size([224, 224, 3]) 3\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4)) # 3 row, 4 col\n",
    "print(random_tensor, random_tensor.dtype)\n",
    "\n",
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "print(random_image_size_tensor.shape, random_image_size_tensor.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.2000, 0.4000, 0.6000, 0.8000, 1.0000, 1.2000, 1.4000, 1.6000,\n",
      "        1.8000, 2.0000, 2.2000, 2.4000, 2.6000, 2.8000, 3.0000, 3.2000, 3.4000,\n",
      "        3.6000, 3.8000, 4.0000, 4.2000, 4.4000, 4.6000, 4.8000, 5.0000, 5.2000,\n",
      "        5.4000, 5.6000, 5.8000, 6.0000, 6.2000, 6.4000, 6.6000, 6.8000, 7.0000,\n",
      "        7.2000, 7.4000, 7.6000, 7.8000, 8.0000, 8.2000, 8.4000, 8.6000, 8.8000,\n",
      "        9.0000, 9.2000, 9.4000, 9.6000, 9.8000])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(start=0, end= 10, step=0.2)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.float32 cpu\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "print(float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device)\n",
    "\n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "print(float_16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5614, 0.2599, 0.5349],\n",
      "        [0.8911, 0.2451, 0.6342],\n",
      "        [0.9663, 0.9709, 0.5817]])\n",
      "tensor([[10.5614, 10.2599, 10.5349],\n",
      "        [10.8911, 10.2451, 10.6342],\n",
      "        [10.9663, 10.9709, 10.5817]])\n",
      "tensor([[1.6842, 0.7798, 1.6046],\n",
      "        [2.6733, 0.7354, 1.9027],\n",
      "        [2.8990, 2.9126, 1.7451]])\n",
      "tensor([[1.1228, 0.5199, 1.0697],\n",
      "        [1.7822, 0.4903, 1.2685],\n",
      "        [1.9327, 1.9417, 1.1634]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,3)\n",
    "print(tensor)\n",
    "print(tensor + 10)\n",
    "print(tensor * 3)\n",
    "print(tensor + tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.\n",
    "\n",
    "PyTorch implements matrix multiplication functionality in the torch.matmul() method.\n",
    "\n",
    "The main two rules for matrix multiplication to remember are:\n",
    "\n",
    "1. The inner dimensions must match:\n",
    "\n",
    "- (3, 2) @ (3, 2) won't work\n",
    "- (2, 3) @ (3, 2) will work\n",
    "- (3, 2) @ (2, 3) will work\n",
    "\n",
    "2. The resulting matrix has the shape of the outer dimensions:\n",
    "\n",
    "- (2, 3) @ (3, 2) -> (2, 2)\n",
    "- (3, 2) @ (2, 3) -> (3, 3)\n",
    "\n",
    "For a tensor variable with values [1, 2, 3]:\n",
    "\n",
    "Operation\tCalculation\tCode\n",
    "- Element-wise multiplication\t[1x1, 2x2, 3x3] = [1, 4, 9]\ttensor * tensor\n",
    "- Matrix multiplication\t[1x1 + 2x2 + 3x3] = [14]\ttensor.matmul(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor * tensor)\n",
    "print(tensor.matmul(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of tensor mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the ways to do this is with a transpose (switch the dimensions of a given tensor).\n",
    "- tensor_A -> tensor_A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "tensor([[ 7., 20.],\n",
      "        [24., 44.],\n",
      "        [45., 72.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(tensor_A, tensor_B.T))\n",
    "print(tensor_A * tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning example\n",
    "\n",
    "torch.nn.Linear: Creates a linear layer that computes the output as output = x * W^T + b, where:\n",
    "W is a weights matrix (randomly initialized),\n",
    "b is a bias vector (randomly initialized).\n",
    "Parameters:\n",
    "in_features=2: The input tensor must have an inner dimension of size 2. For example, the input shape could be (batch_size, 2).\n",
    "out_features=6: The output tensor will have an inner dimension of size 6. For example, the output shape will be (batch_size, 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Set a manual seed for reproducibility\n",
    "torch.manual_seed(42) # Ensures that the randomly initialized weights in the linear layer are the same every time the code is run\n",
    "# Define a linear transformation layer \n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A # input layer\n",
    "output = linear(x) # output layer = X * W.T + bias\n",
    "# A bias vector of shape (6,) is added to each row of the result.\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (aggregation)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "tensor(0)\n",
      "tensor(90)\n",
      "tensor(45., dtype=torch.float16)\n",
      "tensor(450)\n",
      "tensor(9)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "print(x)\n",
    "print(x.min())\n",
    "print(x.max())\n",
    "print(x.type(torch.float16).mean()) # have to define the datatype\n",
    "print(x.sum())\n",
    "\n",
    "print(x.argmax()) #index of max value\n",
    "print(x.argmin()) #index pf min value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n",
      "torch.uint8\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([10, 20, 30], dtype = torch.float16)\n",
    "print(x.dtype)\n",
    "y = x.type(torch.uint8)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, squeezing and unsqueezing\n",
    "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
    "\n",
    "To do so, some popular methods are:\n",
    "\n",
    "- torch.reshape(input, shape)\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n",
    "- Tensor.view(shape)\tReturns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "- torch.stack(tensors, dim=0)\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "- torch.squeeze(input)\tSqueezes input to remove all the dimenions with value 1.\n",
    "- torch.unsqueeze(input, dim)\tReturns input with a dimension value of 1 added at dim.\n",
    "- torch.permute(input, dims)\tReturns a view of the original input with its dimensions permuted (rearranged) to dims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting PyTorch to run on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n",
      "1\n",
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) # if yes -> GPU is available\n",
    "\n",
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Number fo GPUs availabe for PyTorch\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "# Create tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Instead, copy the tensor back to cpu\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tensor_back_on_cpu \u001b[38;5;241m=\u001b[39m tensor_on_gpu\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()\n",
    "\n",
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

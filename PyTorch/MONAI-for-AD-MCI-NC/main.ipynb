{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of AD vs MCI vs NC Using the ResNet Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get update\n",
    "! pip install -r requirements.txt\n",
    "! sudo apt install libgl1 -y\n",
    "\n",
    "#! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.10' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import shutil\n",
    "import data_manager as DM\n",
    "# import torchvision.models as models\n",
    "import torchvision.models.video as models\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "import data_setup, engine\n",
    "from helper_functions import plot_loss_curves\n",
    "from data_setup import create_dataloaders\n",
    "import engine\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "from helper_functions import plot_loss_curves, plot_roc_auc\n",
    "import torchio as tio\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from monai.networks.nets import DenseNet121\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from monai.transforms import Compose, Resize, ScaleIntensity, NormalizeIntensity, RandFlip\n",
    "import random\n",
    "from monai.bundle import download, load\n",
    "from transformers import pipeline, AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the parrent path to current path because data is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "parrent_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "sys.path.append(parrent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage data:\n",
    "\n",
    "✔ Read subject IDs from each sheet in Subject list.xlsx.\n",
    "\n",
    "✔ Create Data/AD, Data/MCI, Data/NC folders.\n",
    "\n",
    "✔ Find std_T1.nii for each subject inside ADNI/{subject_id}/.\n",
    "\n",
    "✔ Copy & renames the file to Data/{category}/{subject_id}.nii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "excel_file = \"../Subject_list.xlsx\"\n",
    "source_root = \"ADNI\"\n",
    "destination_root = \"Data\"\n",
    "if os.path.join(destination_root):\n",
    "   os.system('rm -r Data')\n",
    "source_dir = \"../\"\n",
    "image_type = \"std_T1\"\n",
    "DM.copy_data(image_type, excel_file,source_root,source_dir, destination_root,categories)\n",
    "image_type = \"SUV\"\n",
    "DM.copy_data(image_type, excel_file,source_root,source_dir, destination_root,categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many subjects do we have in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"Data\"\n",
    "\n",
    "for c in categories:\n",
    "    path_train = os.path.join(data_root, 'train', c)\n",
    "    path_test = os.path.join(data_root, 'test', c)\n",
    "\n",
    "    num_train_files = len(os.listdir(path_train))\n",
    "    print(f\"{c} train: {num_train_files} files\")\n",
    "\n",
    "    num_test_files = len(os.listdir(path_test))\n",
    "    print(f\"{c} test: {num_test_files} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MONAI DenseNET121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "\n",
    "# MRI subnetwork\n",
    "mri_model = DenseNet121(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,           # Only MRI\n",
    "    out_channels=1024        # Feature vector\n",
    ")\n",
    "\n",
    "# PET subnetwork\n",
    "pet_model = DenseNet121(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,           # Only PET\n",
    "    out_channels=1024        # Feature vector\n",
    ")\n",
    "\n",
    "# Late Fusion Classifier\n",
    "class LateFusionModel(nn.Module):\n",
    "    def __init__(self, mri_model, pet_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.mri_model = mri_model\n",
    "        self.pet_model = pet_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.6),  # Increase dropout rate\n",
    "            nn.Linear(in_features=2048, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mri, pet = x[:, 0:1], x[:, 1:2]  # Split channels: [B, 1, D, H, W]\n",
    "        mri_feat = self.mri_model(mri)\n",
    "        pet_feat = self.pet_model(pet)\n",
    "        combined = torch.cat([mri_feat, pet_feat], dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# Instantiate late fusion model\n",
    "Monai3d = LateFusionModel(mri_model, pet_model, num_classes=3)\n",
    "\n",
    "# Print model summary\n",
    "summary(model=Monai3d,\n",
    "        input_size=(1, 2, img_size, img_size, img_size),  # (batch_size, channels, D, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader: Prepare the data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global params\n",
    "batch_size = 64\n",
    "random.seed(20)\n",
    "\n",
    "# Base transform\n",
    "transform = Compose([\n",
    "    Resize(spatial_size=(img_size, img_size, img_size), mode='trilinear'),\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-5),\n",
    "])\n",
    "\n",
    "# Your custom intensity adjustment function\n",
    "def random_intensity_adjust(img):\n",
    "    factor = random.uniform(0.8, 1.2)\n",
    "    return img * factor\n",
    "\n",
    "augmentation_transform = Compose([\n",
    "    Resize(spatial_size=(img_size, img_size, img_size), mode='trilinear'),\n",
    "    # transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.RandomVerticalFlip(p=1),\n",
    "    transforms.RandomRotation(degrees=10),  # Add random rotation\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translation\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-5),  # Normalize\n",
    "    lambda x: random_intensity_adjust(x)\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare paths\n",
    "train_data_path = os.path.join(data_root, \"train\")\n",
    "test_data_path = os.path.join(data_root, \"test\")\n",
    "\n",
    "# Load DataLoaders\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "    train_dir=train_data_path,\n",
    "    test_dir=test_data_path,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    augmentation_transform=augmentation_transform\n",
    ")\n",
    "\n",
    "# Print info\n",
    "print(' ')\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(' ')\n",
    "print(\"Number of training samples:\", len(train_dataloader.dataset))\n",
    "print(\"Number of testing samples:\", len(test_dataloader.dataset))\n",
    "\n",
    "\n",
    "# Visualize samples\n",
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "print(image_batch.shape, label_batch.shape)\n",
    "\n",
    "# Randomly sample n PET middle slices\n",
    "num_images = 16\n",
    "batch_size = image_batch.shape[0]\n",
    "random_indices = torch.randint(0, batch_size, (num_images,))\n",
    "mid_slice_idx = image_batch.shape[4] // 2  # Depth index\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = random_indices[i]\n",
    "    img = image_batch[idx, 1, :, :, mid_slice_idx].detach().cpu().numpy()  # PET slice\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"Label: {class_names[label_batch[idx].item()]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the device\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Working on device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = Monai3d\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "# loss_fn = torch.nn.NLLLoss()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.6)\n",
    "\n",
    "# Train the classifier head of the pretrained ViT feature extractor model\n",
    "torch.manual_seed(21)\n",
    "torch.cuda.manual_seed(21)\n",
    "\n",
    "model_results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=30,\n",
    "    device=device,\n",
    "    scheduler = scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "\n",
    "# Step 1: Collect predictions and ground-truth labels\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch  # Unpack if batch is a tuple\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)  # <--- You were missing this line\n",
    "        probs = torch.softmax(outputs, dim=1)  # Get class probabilities\n",
    "        \n",
    "        all_preds.append(probs.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_score = np.concatenate(all_preds, axis=0)      # shape: (num_samples, num_classes)\n",
    "y_true = np.concatenate(all_labels, axis=0)      # shape: (num_samples,)\n",
    "\n",
    "# Step 2: Binarize the labels for ROC computation\n",
    "n_classes = y_score.shape[1]\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
    "\n",
    "# Step 3: Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Step 4 (Optional): Compute micro-average and macro-average\n",
    "# Micro-average\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true_bin.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Macro-average\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "mean_tpr /= n_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Step 5: Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot per-class ROC\n",
    "colors = cycle(['blue', 'green', 'red', 'orange', 'purple'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot micro/macro average ROC\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"], linestyle='--', color='deeppink',\n",
    "#          label=f'Micro-average (AUC = {roc_auc[\"micro\"]:.2f})', linewidth=2)\n",
    "\n",
    "# plt.plot(fpr[\"macro\"], tpr[\"macro\"], linestyle='--', color='navy',\n",
    "#          label=f'Macro-average (AUC = {roc_auc[\"macro\"]:.2f})', linewidth=2)\n",
    "\n",
    "# Plot diagonal line for random guess\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "# Final touches\n",
    "plt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
    "plt.title('Multi-class ROC Curve', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, target_dir, model_name):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    save_path = os.path.join(target_dir, model_name)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "save_model(model=model,\n",
    "            target_dir=\"models\",\n",
    "            model_name=\"MONAI3D_AD_MCI_NC.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from data_setup import MultiModalSeparateNiiDataset\n",
    "\n",
    "torch.manual_seed(21)\n",
    "torch.cuda.manual_seed_all(21)\n",
    "model.eval()\n",
    "\n",
    "valid_dataset = MultiModalSeparateNiiDataset(\"Data/valid\", categories, transform)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "test_loss, test_acc, metrics, classification_summary = engine.test_step(\n",
    "    model=model,\n",
    "    dataloader=valid_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "for class_index, sensitivity in metrics.items():\n",
    "    print(f\"Class {class_index}: Sensitivity = {sensitivity:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of AD vs MCI vs NC Using the ResNet Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get update\n",
    "! pip install -r requirements.txt\n",
    "! sudo apt install libgl1 -y\n",
    "\n",
    "#! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "import shutil\n",
    "import data_manager as DM\n",
    "# import torchvision.models as models\n",
    "import torchvision.models.video as models\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "import data_setup, engine\n",
    "from helper_functions import plot_loss_curves\n",
    "from data_setup import create_dataloaders\n",
    "import engine\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torch.utils.data import DataLoader\n",
    "from helper_functions import plot_loss_curves\n",
    "import torchio as tio\n",
    "from torchvision.models.video import R3D_18_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from monai.networks.nets import DenseNet121\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from monai.transforms import Compose, Resize, ScaleIntensity, NormalizeIntensity, RandFlip\n",
    "import random\n",
    "from monai.bundle import download, load\n",
    "from transformers import pipeline, AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the parrent path to current path because data is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "parrent_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "sys.path.append(parrent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage data:\n",
    "\n",
    "✔ Read subject IDs from each sheet in Subject list.xlsx.\n",
    "\n",
    "✔ Create Data/AD, Data/MCI, Data/NC folders.\n",
    "\n",
    "✔ Find std_T1.nii for each subject inside ADNI/{subject_id}/.\n",
    "\n",
    "✔ Copy & renames the file to Data/{category}/{subject_id}.nii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"AD\", \"MCI\", \"NC\"]\n",
    "excel_file = \"../Subject list.xlsx\"\n",
    "source_root = \"ADNI\"\n",
    "destination_root = \"Data\"\n",
    "if os.path.join(destination_root):\n",
    "   os.system('rm -r Data')\n",
    "source_dir = \"../\"\n",
    "image_type = \"GM\"\n",
    "DM.copy_data(image_type, excel_file,source_root,source_dir, destination_root,categories)\n",
    "image_type = \"SUV_GM\"\n",
    "DM.copy_data(image_type, excel_file,source_root,source_dir, destination_root,categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many subjects do we have in each group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"Data\"\n",
    "\n",
    "for c in categories:\n",
    "    path_train = os.path.join(data_root, 'train', c)\n",
    "    path_test = os.path.join(data_root, 'test', c)\n",
    "\n",
    "    num_train_files = len(os.listdir(path_train))\n",
    "    print(f\"{c} train: {num_train_files} files\")\n",
    "\n",
    "    num_test_files = len(os.listdir(path_test))\n",
    "    print(f\"{c} test: {num_test_files} files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MONAI DenseNET121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "\n",
    "# MRI subnetwork\n",
    "mri_model = DenseNet121(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,           # Only MRI\n",
    "    out_channels=1024        # Feature vector\n",
    ")\n",
    "\n",
    "# PET subnetwork\n",
    "pet_model = DenseNet121(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,           # Only PET\n",
    "    out_channels=1024        # Feature vector\n",
    ")\n",
    "\n",
    "# Late Fusion Classifier\n",
    "class LateFusionModel(nn.Module):\n",
    "    def __init__(self, mri_model, pet_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.mri_model = mri_model\n",
    "        self.pet_model = pet_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.6),  # Increase dropout rate\n",
    "            nn.Linear(in_features=2048, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mri, pet = x[:, 0:1], x[:, 1:2]  # Split channels: [B, 1, D, H, W]\n",
    "        mri_feat = self.mri_model(mri)\n",
    "        pet_feat = self.pet_model(pet)\n",
    "        combined = torch.cat([mri_feat, pet_feat], dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# Instantiate late fusion model\n",
    "Monai3d = LateFusionModel(mri_model, pet_model, num_classes=3)\n",
    "\n",
    "# Print model summary\n",
    "summary(model=Monai3d,\n",
    "        input_size=(1, 2, img_size, img_size, img_size),  # (batch_size, channels, D, H, W)\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader: Prepare the data for model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global params\n",
    "batch_size = 64\n",
    "random.seed(20)\n",
    "\n",
    "# Base transform\n",
    "transform = Compose([\n",
    "    Resize(spatial_size=(img_size, img_size, img_size), mode='trilinear'),\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-5),\n",
    "])\n",
    "\n",
    "# Your custom intensity adjustment function\n",
    "def random_intensity_adjust(img):\n",
    "    factor = random.uniform(0.8, 1.2)\n",
    "    return img * factor\n",
    "\n",
    "augmentation_transform = Compose([\n",
    "    Resize(spatial_size=(img_size, img_size, img_size), mode='trilinear'),\n",
    "    # transforms.RandomHorizontalFlip(p=1),\n",
    "    transforms.RandomVerticalFlip(p=1),\n",
    "    transforms.RandomRotation(degrees=10),  # Add random rotation\n",
    "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random translation\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-5),  # Normalize\n",
    "    lambda x: random_intensity_adjust(x)\n",
    "])\n",
    "\n",
    "\n",
    "# Prepare paths\n",
    "train_data_path = os.path.join(data_root, \"train\")\n",
    "test_data_path = os.path.join(data_root, \"test\")\n",
    "\n",
    "# Load DataLoaders\n",
    "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
    "    train_dir=train_data_path,\n",
    "    test_dir=test_data_path,\n",
    "    transform=transform,\n",
    "    batch_size=batch_size,\n",
    "    augmentation_transform=augmentation_transform\n",
    ")\n",
    "\n",
    "# Print info\n",
    "print(' ')\n",
    "print(f\"Class names: {class_names}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(' ')\n",
    "print(\"Number of training samples:\", len(train_dataloader.dataset))\n",
    "print(\"Number of testing samples:\", len(test_dataloader.dataset))\n",
    "\n",
    "\n",
    "# Visualize samples\n",
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "print(image_batch.shape, label_batch.shape)\n",
    "\n",
    "# Randomly sample n PET middle slices\n",
    "num_images = 16\n",
    "batch_size = image_batch.shape[0]\n",
    "random_indices = torch.randint(0, batch_size, (num_images,))\n",
    "mid_slice_idx = image_batch.shape[4] // 2  # Depth index\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 6))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    idx = random_indices[i]\n",
    "    img = image_batch[idx, 1, :, :, mid_slice_idx].detach().cpu().numpy()  # PET slice\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"Label: {class_names[label_batch[idx].item()]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the device\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Working on device: {device}\")\n",
    "\n",
    "# Model\n",
    "model = Monai3d\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "# loss_fn = torch.nn.NLLLoss()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.6)\n",
    "\n",
    "# Train the classifier head of the pretrained ViT feature extractor model\n",
    "torch.manual_seed(21)\n",
    "torch.cuda.manual_seed(21)\n",
    "\n",
    "model_results = engine.train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=30,\n",
    "    device=device,\n",
    "    scheduler = scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, target_dir, model_name):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    save_path = os.path.join(target_dir, model_name)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "# save_model(model=model,\n",
    "#             target_dir=\"models\",\n",
    "#             model_name=\"MONAI3D_AD_NC.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# import os\n",
    "# import torch\n",
    "# import nibabel as nib\n",
    "# from torch.utils.data import Dataset\n",
    "# from torchvision import transforms\n",
    "# from engine import test_step\n",
    "\n",
    "# model.eval()  \n",
    "# model.to(device)\n",
    "\n",
    "# class TestNiiDataset(Dataset):\n",
    "#     def __init__(self, root_dir, transform=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         self.samples = []\n",
    "#         self.label_map = {'AD': 0, 'MCI': 1, 'NC': 2}\n",
    "\n",
    "#         for label_name in os.listdir(root_dir):\n",
    "#             label_dir = os.path.join(root_dir, label_name)\n",
    "#             if os.path.isdir(label_dir):\n",
    "#                 for fname in os.listdir(label_dir):\n",
    "#                     if fname.endswith('.nii') or fname.endswith('.nii.gz'):\n",
    "#                         self.samples.append((os.path.join(label_dir, fname), self.label_map[label_name]))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         nii_path, label = self.samples[idx]\n",
    "#         img = nib.load(nii_path).get_fdata()\n",
    "#         img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # add channel dimension\n",
    "\n",
    "#         if self.transform:\n",
    "#             img = self.transform(img)\n",
    "\n",
    "#         return img, label\n",
    "\n",
    "\n",
    "# test_dataset = TestNiiDataset(\"Data/test\")\n",
    "# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# test_loss, test_acc, test_metrics, test_report = test_step(\n",
    "#     model=model,\n",
    "#     dataloader=test_loader,\n",
    "#     loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# print(\"Test accuracy:\", test_acc)\n",
    "# print(\"Metrics:\", test_metrics)\n",
    "# print(\"Classification report:\\n\", test_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

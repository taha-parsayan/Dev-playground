{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser, JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "current_path = os.getcwd()\n",
    "parrent_path = os.path.abspath(os.path.join(current_path, '..'))\n",
    "sys.path.append(parrent_path)\n",
    "\n",
    "from Update_Git import git_add, git_commit, git_push\n",
    "\n",
    "file_path = os.path.join(current_path, 'Test_5.ipynb')\n",
    "git_add(file_path)\n",
    "git_commit('Updated test 5')\n",
    "git_push('main')\n",
    "\n",
    "os.environ.pop(\"OPENAI_API_KEY\", None) # Because it loads a key from some place I dont know!\n",
    "env_path = os.path.join(current_path, \".env\")\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Hello! How can I assist you today?\n",
      "AI:  Based on the provided information, the document seems to be related to a research paper or article in the field of neuroscience or neuroimaging. It includes authors such as Stephen M. Smith, Karla L. Miller, and Paul M. Matthews, among others. The document likely discusses topics related to brain imaging, diffusion MRI, and possibly methods for analyzing brain connectivity.\n",
      "AI:  Yes, the document appears to be related to a toolbox called FreeSurfer. FreeSurfer is a software suite used for analyzing and visualizing structural and functional neuroimaging data. It is commonly used in the field of neuroscience for tasks such as brain segmentation, cortical surface reconstruction, and volumetric analysis. The document likely provides information on the usage, interoperation, and download of the FreeSurfer toolbox.\n",
      "AI:  In addition to the usage and interoperation of the FreeSurfer toolbox, the document may also cover topics such as the various packages available within FreeSurfer for different neuroimaging analyses, the privacy policy of the software, information about the developers, statistics related to its usage, and any disclaimers or code of conduct associated with using FreeSurfer. It may also provide details on how to contact the developers for support or feedback, as well as information on the cookie statement and mobile view options for using FreeSurfer.\n",
      "AI:  The authors listed in the document include a large group of researchers and scientists from various institutions. Some of the authors mentioned in the document are Dale, Anders M.; Jernigan, Terry L.; Brown, Sandra A.; Dowling, Gayathri J.; Grant, Steven J.; Constable, R. Todd; Baskin-Sommers, Arielle; Madden, Pamela A.; Heath, Andrew C.; Glaser, Paul; Anokhin, Andrey P.; Steinberg, Joel; Hettema, John M.; Fuemmeler, Bernard; Charness, Michael E.; Lisdahl, Krista; Larson, Christine; Florsheim, Paul; Potter, Alexandra; Ivanova, Masha; Dumas, Julie A.; Smith, Stephen M.; Miller, Karla L.; Matthews, Paul M.; Dragonu, Iulius; Zhang, Hui; Alexander, Daniel C.; Daducci, Alessandro; Rorden, Christopher; McCarthy, Paul; Webster, Matthew; Vidaurre, Diego; Vallee, Emmanuel; Hernandez-Fernandez, Moises; Jbabdi, Saad; Sotiropoulos, Stamatios N.; Douaud, GwenaÃ«lle; Griffanti, Ludovica; Andersson, Jesper L. R.; Bangerter, Neal K.; Jenkinson, Mark; Allgaier, Nicholas A.; Yurgelun-Todd, Deborah A.; Renshaw, Perry F.; Prescot, Andrew; McGlade, Erin; Huber, Rebekah; Mason, Michael J.; Mruzek, Daniel W.; and others.\n",
      "AI:  Yes, the document likely includes information on how to use the FreeSurfer toolbox. It may provide instructions on how to download and install the software, as well as guidance on how to preprocess neuroimaging data, run specific analyses, and interpret the results generated by FreeSurfer. Additionally, the document may include tutorials, examples, and tips on using the various features and functions of FreeSurfer for brain imaging research.\n",
      "AI:  Based on the information provided, you are using a morphed spherical method to average across subjects for statistical analysis with the mri_glmfit tool. This method likely involves morphing individual brain structures into a common spherical space to facilitate group-level statistical analysis using a general linear model (GLM). The mri_glmfit tool is likely used to perform voxel-wise statistical tests across subjects, taking into account the morphed spherical representations of brain structures.\n",
      "AI:  Yes, I am an AI assistant powered by GPT-3 technology developed by OpenAI. How can I assist you further today?\n",
      "AI:  You're welcome! Feel free to return if you have any more questions in the future. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# Function to load and split documents from a given URL\n",
    "def document_loader(url):\n",
    "    loader = WebBaseLoader(url)  # Load the document from the web\n",
    "    docs = loader.load()  # Extract the content\n",
    "    \n",
    "    # Split the document into smaller chunks for processing\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,  # Each chunk has a max size of 200 characters\n",
    "        chunk_overlap=50  # Overlapping of 50 characters between chunks for context continuity\n",
    "    )\n",
    "    split_docs = splitter.split_documents(docs)  # Split the documents\n",
    "\n",
    "    return split_docs  # Return the processed document chunks\n",
    "\n",
    "# Function to create a FAISS vector database\n",
    "def create_db(docs):\n",
    "    embedding = OpenAIEmbeddings()  # Generate embeddings using OpenAI\n",
    "    vector_store = FAISS.from_documents(docs, embedding=embedding)  # Store documents in FAISS index\n",
    "    return vector_store  # Return the FAISS vector store\n",
    "\n",
    "# Function to create a retrieval chain using the vector store\n",
    "def create_chain(vector_store):\n",
    "    model = ChatOpenAI(\n",
    "        model='gpt-3.5-turbo',  # Use GPT-3.5-turbo model\n",
    "        temperature=0.4  # Set temperature for response variability\n",
    "    )\n",
    "\n",
    "    # Define a prompt template for the chatbot\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Answer the user's question based on the given context: {context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    parser = StrOutputParser()  # Convert output to a string format\n",
    "\n",
    "    # Create the document processing chain\n",
    "    chain = create_stuff_documents_chain(\n",
    "        llm=model,\n",
    "        prompt=prompt,\n",
    "        output_parser=parser\n",
    "    )\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_kwaargs = {\"k\": 3})  # Convert vector store into a retriever\n",
    "    retrieval_chain = create_retrieval_chain(\n",
    "        retriever, \n",
    "        chain\n",
    "        )  # Create a retrieval-based chain\n",
    "\n",
    "    return retrieval_chain  # Return the retrieval chain\n",
    "\n",
    "\n",
    "def process_chat(chain, question, history):\n",
    "    # Query the retrieval chain with a sample question\n",
    "    response = chain.invoke({\n",
    "    \"input\": question,\n",
    "    \"chat_history\": history,\n",
    "    \"context\": docs\n",
    "})\n",
    "\n",
    "    # Print the answer from the model\n",
    "    return response[\"answer\"]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    docs = document_loader(\"https://en.wikipedia.org/wiki/FreeSurfer\")\n",
    "    vector_store = create_db(docs)\n",
    "    chain = create_chain(vector_store)\n",
    "\n",
    "    chat_history = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = process_chat(chain, user_input, chat_history)\n",
    "        chat_history.append(HumanMessage(content=user_input))\n",
    "        chat_history.append(AIMessage(content=response))\n",
    "        print(\"AI: \", response)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This example shows how to use the StrOutputParser to parse the output of a language model into a string. This is useful when you want to extract a specific piece of information from the output.\n",
    "\n",
    "It is a part of the LangChain framework, which is used for building applications with language models.\n",
    "\n",
    "Prompt -> llm -> parser\n",
    "\n",
    "Parser types:\n",
    "1. StrOutputParser\n",
    "2. CommaSeparatedListOutputParser\n",
    "3. JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "sys.path.append(parent_dir)\n",
    "from Update_Git import git_add, git_commit, git_push\n",
    "\n",
    "os.environ.pop(\"OPENAI_API_KEY\", None) # Because it loads a key from some place I dont know!\n",
    "env_path = os.path.join(current_dir, \".env\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "add_file = os.path.join(current_dir, 'Test_3.ipynb')\n",
    "git_add(add_file)\n",
    "git_commit('Test 3 updated')\n",
    "git_push('main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taha/Documents/Python_codes/Dev-playground/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3672: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Pleasant\n",
      "2. Kind\n",
      "3. Agreeable\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, CommaSeparatedListOutputParser, JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# llm model\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# prompt\n",
    "def call_string_output_parser():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an AI assisstant. Give me 3 synonyms for the following word.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    # Output parser\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    # The parser will convert the output of the LLM to a string\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    # The output of llm is a AI message, so we need to convert it to a string\n",
    "    # The outout of the parser is a string\n",
    "\n",
    "    return chain.invoke(\"nice\")\n",
    "                        \n",
    "print(call_string_output_parser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignancy', 'carcinoma', 'neoplasm']\n"
     ]
    }
   ],
   "source": [
    "def call_list_output_parser():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Give me 3 synonyms for the following word, separated by commas.\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    parser = CommaSeparatedListOutputParser() # Output is a list of strings\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke(\"cancer\")\n",
    "\n",
    "print(call_list_output_parser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "def call_json_output_parser():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Extract information from the following phrase.\\n Formatting instructuions: {format_instructions}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    # make a class with the parameters we want to extract from the LLM output\n",
    "    class Person(BaseModel):\n",
    "        name: str = Field(description=\"The name of the person\")\n",
    "        age: int = Field(description=\"The age of the person\")\n",
    "    \n",
    "    # create a parser using the class\n",
    "    parser = JsonOutputParser(pydantic_object=Person)\n",
    "\n",
    "    # chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    # print(parser.get_format_instructions())\n",
    "\n",
    "    return chain.invoke({\n",
    "        \"input\": \"John is 30 years old.\",\n",
    "         \"format_instructions\": parser.get_format_instructions()\n",
    "\n",
    "    })\n",
    "\n",
    "print(call_json_output_parser())\n",
    "# Output is a dictionary !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recipie': 'ghormesabzi', 'ingredients': ['rice', 'beans', 'beef', 'lime', 'herbs']}\n"
     ]
    }
   ],
   "source": [
    "def call_json_output_parser():\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Extract information from the following phrase.\\n Formatting instructuions: {format_instructions}\"),\n",
    "        (\"human\", \"{input}\")\n",
    "    ])\n",
    "\n",
    "    class Food(BaseModel):\n",
    "        recipie: str = Field(description=\"The name of the recipie\")\n",
    "        ingredients: list = Field(description=\"Ingredients\")\n",
    "    \n",
    "    parser = JsonOutputParser(pydantic_object=Food)\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    return chain.invoke({\n",
    "        \"input\": \"The ingredients for ghormesabzi are rice, beans, beef, lime, and herbs.\",\n",
    "         \"format_instructions\": parser.get_format_instructions()\n",
    "\n",
    "    })\n",
    "\n",
    "print(call_json_output_parser())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
